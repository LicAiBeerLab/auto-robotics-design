{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pymoo.algorithms.soo.nonconvex.pso import PSO\n",
    "from pymoo.core.problem import StarmapParallelization\n",
    "from auto_robot_design.generator.restricted_generator.two_link_generator import TwoLinkGenerator, visualize_constrains\n",
    "from pymoo.algorithms.moo.age2 import AGEMOEA2\n",
    "\n",
    "from auto_robot_design.optimization.saver import (\n",
    "    ProblemSaver, )\n",
    "from auto_robot_design.description.builder import jps_graph2pinocchio_robot\n",
    "from auto_robot_design.description.utils import draw_joint_point\n",
    "from auto_robot_design.optimization.problems import CalculateCriteriaProblemByWeigths, get_optimizing_joints, CalculateMultiCriteriaProblem, MultiCriteriaProblem\n",
    "from auto_robot_design.optimization.optimizer import PymooOptimizer\n",
    "from auto_robot_design.pinokla.calc_criterion import ActuatedMass, EffectiveInertiaCompute, ImfCompute, ManipCompute, MovmentSurface, NeutralPoseMass, TranslationErrorMSE, ManipJacobian\n",
    "from auto_robot_design.pinokla.criterion_agregator import CriteriaAggregator\n",
    "from auto_robot_design.pinokla.criterion_math import ImfProjections\n",
    "from auto_robot_design.pinokla.default_traj import add_auxilary_points_to_trajectory, convert_x_y_to_6d_traj_xz, get_simple_spline, get_vertical_trajectory, create_simple_step_trajectory, get_workspace_trajectory, get_horizontal_trajectory\n",
    "from auto_robot_design.optimization.rewards.reward_base import PositioningReward, PositioningConstrain, PositioningErrorCalculator, RewardManager\n",
    "from auto_robot_design.optimization.rewards.jacobian_and_inertia_rewards import HeavyLiftingReward, AccelerationCapability, MeanHeavyLiftingReward, MinAccelerationCapability\n",
    "from auto_robot_design.optimization.rewards.pure_jacobian_rewards import EndPointZRRReward, VelocityReward, ForceEllipsoidReward, ZRRReward, MinForceReward, MinManipulabilityReward\n",
    "from auto_robot_design.optimization.rewards.inertia_rewards import MassReward\n",
    "from auto_robot_design.description.actuators import TMotor_AK10_9, TMotor_AK60_6, TMotor_AK70_10, TMotor_AK80_64, TMotor_AK80_9\n",
    "from auto_robot_design.description.builder import ParametrizedBuilder, DetailedURDFCreatorFixedEE, jps_graph2pinocchio_robot, MIT_CHEETAH_PARAMS_DICT\n",
    "from auto_robot_design.generator.topologies.graph_manager_2l import GraphManager2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "list(itertools.permutations([0,1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10**7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GraphManager2L()\n",
    "gm.reset()\n",
    "gm.build_main(0.4, fully_actuated=True)\n",
    "gm.set_mutation_ranges()\n",
    "print(gm.mutation_ranges)\n",
    "center = gm.generate_central_from_mutation_range()\n",
    "center[0] = -0.3\n",
    "print(center)\n",
    "graph = gm.get_graph(center)\n",
    "draw_joint_point(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "thickness = MIT_CHEETAH_PARAMS_DICT[\"thickness\"]\n",
    "actuator = MIT_CHEETAH_PARAMS_DICT[\"actuator\"]\n",
    "density = MIT_CHEETAH_PARAMS_DICT[\"density\"]\n",
    "body_density = MIT_CHEETAH_PARAMS_DICT[\"body_density\"]\n",
    "\n",
    "\n",
    "builder = ParametrizedBuilder(DetailedURDFCreatorFixedEE,\n",
    "                              density={\"default\": density, \"G\": body_density},\n",
    "                              thickness={\"default\": thickness, \"EE\": 0.033},\n",
    "                              actuator={\"default\": actuator},\n",
    "                              size_ground=np.array(\n",
    "                                  MIT_CHEETAH_PARAMS_DICT[\"size_ground\"]),\n",
    "                              offset_ground=MIT_CHEETAH_PARAMS_DICT[\"offset_ground_rl\"]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) trajectories\n",
    "\n",
    "workspace_trajectory = convert_x_y_to_6d_traj_xz(\n",
    "    *add_auxilary_points_to_trajectory(get_workspace_trajectory([-0.15, -0.35], 0.14, 0.3, 30, 60)))\n",
    "# ground_symmetric_step = convert_x_y_to_6d_traj_xz(*create_simple_step_trajectory(\n",
    "#     starting_point=[-0.1, -0.31], step_height=0.05, step_width=0.2, n_points=50))\n",
    "\n",
    "ground_symmetric_step1 = convert_x_y_to_6d_traj_xz(*add_auxilary_points_to_trajectory(create_simple_step_trajectory(\n",
    "    starting_point=[-0.14, -0.34], step_height=0.12, step_width=0.28, n_points=200)))\n",
    "\n",
    "ground_symmetric_step2 = convert_x_y_to_6d_traj_xz(*add_auxilary_points_to_trajectory(create_simple_step_trajectory(\n",
    "    starting_point=[-0.14 + 0.015, -0.34], step_height=0.10, step_width=-2*(-0.14 + 0.015), n_points=200)))\n",
    "\n",
    "ground_symmetric_step3 = convert_x_y_to_6d_traj_xz(*add_auxilary_points_to_trajectory(create_simple_step_trajectory(\n",
    "    starting_point=[-0.14 + 0.025 , -0.34], step_height=0.08, step_width=-2*(-0.14 + 0.025), n_points=200)))\n",
    "\n",
    "central_vertical = convert_x_y_to_6d_traj_xz(\n",
    "    *add_auxilary_points_to_trajectory(get_vertical_trajectory(-0.34, 0.12, 0, 200)))\n",
    "\n",
    "left_vertical = convert_x_y_to_6d_traj_xz(\n",
    "    *add_auxilary_points_to_trajectory(get_vertical_trajectory(-0.34, 0.12, -0.12, 200)))\n",
    "\n",
    "right_vertical = convert_x_y_to_6d_traj_xz(\n",
    "    *add_auxilary_points_to_trajectory(get_vertical_trajectory(-0.34, 0.12, 0.12, 200)))\n",
    "# 2) characteristics to be calculated\n",
    "# criteria that either calculated without any reference to points, or calculated through the aggregation of values from all points on trajectory\n",
    "dict_trajectory_criteria = {\n",
    "    \"MASS\": NeutralPoseMass(),\n",
    "    \"POS_ERR\": TranslationErrorMSE()  # MSE of deviation from the trajectory\n",
    "}\n",
    "# criteria calculated for each point on the trajectory\n",
    "dict_point_criteria = {\n",
    "    # Impact mitigation factor along the axis\n",
    "    \"IMF\": ImfCompute(ImfProjections.Z),\n",
    "    \"MANIP\": ManipCompute(MovmentSurface.XZ),\n",
    "    \"Effective_Inertia\": EffectiveInertiaCompute(),\n",
    "    \"Actuated_Mass\": ActuatedMass(),\n",
    "    \"Manip_Jacobian\": ManipJacobian(MovmentSurface.XZ)\n",
    "}\n",
    "# special object that calculates the criteria for a robot and a trajectory\n",
    "crag = CriteriaAggregator(dict_point_criteria, dict_trajectory_criteria, alg_name=\"Open_Loop\")\n",
    "\n",
    "# set the rewards and weights for the optimization task\n",
    "acceleration_capability = MinAccelerationCapability(manipulability_key='Manip_Jacobian',\n",
    "                                                    trajectory_key=\"traj_6d\", error_key=\"error\", actuated_mass_key=\"Actuated_Mass\")\n",
    "min_velocity = MinManipulabilityReward(\n",
    "    manipulability_key='Manip_Jacobian', trajectory_key=\"traj_6d\", error_key=\"error\")\n",
    "\n",
    "min_force = MinForceReward(\n",
    "    manipulability_key='Manip_Jacobian', trajectory_key=\"traj_6d\", error_key=\"error\")\n",
    "heavy_lifting = HeavyLiftingReward(\n",
    "    manipulability_key='Manip_Jacobian', trajectory_key=\"traj_6d\", error_key=\"error\", mass_key=\"MASS\")\n",
    "\n",
    "# set up special classes for reward calculations\n",
    "error_calculator = PositioningErrorCalculator(\n",
    "    error_key='error', jacobian_key=\"Manip_Jacobian\")\n",
    "soft_constrain = PositioningConstrain(\n",
    "    error_calculator=error_calculator, points=[workspace_trajectory])\n",
    "\n",
    "\n",
    "soft_constrain = PositioningConstrain(\n",
    "    error_calculator=error_calculator, points=[ground_symmetric_step1, ground_symmetric_step2, ground_symmetric_step3, central_vertical, left_vertical, right_vertical])\n",
    "\n",
    "#\n",
    "# manager should be filled with trajectories and rewards using the manager API\n",
    "reward_manager = RewardManager(crag=crag)\n",
    "\n",
    "reward_manager.add_trajectory(ground_symmetric_step1, 0)\n",
    "reward_manager.add_trajectory(ground_symmetric_step2, 1)\n",
    "reward_manager.add_trajectory(ground_symmetric_step3, 2)\n",
    "\n",
    "reward_manager.add_trajectory(central_vertical, 3)\n",
    "reward_manager.add_trajectory(left_vertical, 4)\n",
    "reward_manager.add_trajectory(right_vertical, 5)\n",
    "\n",
    "reward_manager.add_reward(acceleration_capability, 0, 1)\n",
    "reward_manager.add_reward(acceleration_capability, 1, 1)\n",
    "reward_manager.add_reward(acceleration_capability, 2, 1)\n",
    "\n",
    "reward_manager.add_reward(heavy_lifting, 3, 1)\n",
    "reward_manager.add_reward(heavy_lifting, 4, 1)\n",
    "reward_manager.add_reward(heavy_lifting, 5, 1)\n",
    "\n",
    "reward_manager.add_trajectory_aggregator([0, 1, 2], 'mean')\n",
    "reward_manager.add_trajectory_aggregator([3, 4, 5], 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Circle, PathPatch\n",
    "from matplotlib.path import Path\n",
    "draw_joint_point(graph)\n",
    "# Parameters for the circles\n",
    "center = (0, 0)\n",
    "x = 0.29900169\n",
    "radius1 = ((0.4-x)**2+0.03**2)**0.5+(0.03**2+x**2)**0.5 \n",
    "radius2 = (0.03**2+x**2)**0.5  - ((0.4-x)**2+0.03**2)**0.5\n",
    "\n",
    "# Create a figure and axis\n",
    "ax = plt.gca()\n",
    "\n",
    "# Define the outer and inner circles\n",
    "outer_circle = Circle(center, radius1, edgecolor='black', facecolor='none')\n",
    "inner_circle = Circle(center, radius2, edgecolor='black', facecolor='none')\n",
    "\n",
    "# Add circles to the plot\n",
    "ax.add_patch(outer_circle)\n",
    "ax.add_patch(inner_circle)\n",
    "\n",
    "# Create the paths for the circles\n",
    "outer_path = Path.circle(center=center, radius=radius1)\n",
    "inner_path = Path.circle(center=center, radius=radius2)\n",
    "\n",
    "# Create the path patch for the area between the circles\n",
    "vertices = np.concatenate([outer_path.vertices, inner_path.vertices[::-1]])\n",
    "codes = np.concatenate([outer_path.codes, inner_path.codes])\n",
    "path = Path(vertices, codes)\n",
    "patch = PathPatch(path, facecolor='blue', alpha=0.3)\n",
    "\n",
    "# Add the path patch to the plot\n",
    "ax.add_patch(patch)\n",
    "for _, trajectory in reward_manager.trajectories.items():\n",
    "    plt.plot(trajectory[:, 0], trajectory[:, 2])\n",
    "\n",
    "plt.plot(workspace_trajectory[:, 0], workspace_trajectory[:, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for _, trajectory in reward_manager.trajectories.items():\n",
    "    plt.plot(trajectory[:, 0], trajectory[:, 2])\n",
    "\n",
    "plt.plot(workspace_trajectory[:, 0], workspace_trajectory[:, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate multiprocessing\n",
    "N_PROCESS = 8\n",
    "pool = multiprocessing.Pool(N_PROCESS)\n",
    "runner = StarmapParallelization(pool.starmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "population_size = 32\n",
    "n_generations = 10\n",
    "\n",
    "# create the problem for the current optimization\n",
    "problem = MultiCriteriaProblem(gm, builder, reward_manager,\n",
    "                               soft_constrain, elementwise_runner=runner, Actuator=actuator)\n",
    "\n",
    "saver = ProblemSaver(problem, \"test\", True)\n",
    "saver.save_nonmutable()\n",
    "algorithm = AGEMOEA2(pop_size=population_size, save_history=True)\n",
    "optimizer = PymooOptimizer(problem, algorithm, saver)\n",
    "\n",
    "res = optimizer.run(\n",
    "    False, **{\n",
    "        \"seed\": 3,\n",
    "        \"termination\": (\"n_gen\", n_generations),\n",
    "        \"verbose\": True\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_history = np.array(optimizer.history[\"F\"]).flatten()\n",
    "history_mean = np.array(optimizer.history[\"Mean\"])\n",
    "plt.scatter(np.arange(len(flatten_history)), flatten_history)\n",
    "plt.show()\n",
    "plt.plot(np.arange(len(history_mean)), history_mean[:, 0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = res.F\n",
    "fl = F.min(axis=0)\n",
    "fu = F.max(axis=0)\n",
    "print(f\"Scale f1: [{fl[0]}, {fu[0]}]\")\n",
    "print(f\"Scale f2: [{fl[1]}, {fu[1]}]\")\n",
    "approx_ideal = F.min(axis=0)\n",
    "approx_nadir = F.max(axis=0)\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(F[:, 0], F[:, 1], s=30, facecolors='none', edgecolors='blue')\n",
    "plt.scatter(approx_ideal[0], approx_ideal[1], facecolors='none',\n",
    "            edgecolors='red', marker=\"*\", s=100, label=\"Ideal Point (Approx)\")\n",
    "plt.scatter(approx_nadir[0], approx_nadir[1], facecolors='none',\n",
    "            edgecolors='black', marker=\"p\", s=100, label=\"Nadir Point (Approx)\")\n",
    "plt.title(\"Objective Space\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "j_moves",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
